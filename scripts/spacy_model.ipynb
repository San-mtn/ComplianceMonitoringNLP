{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download nl_core_news_lg\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data.csv')\n",
    "\n",
    "nlp = spacy.load(\"nl_core_news_lg\")\n",
    "ner_categories = ['ORG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Train set size:\", len(train))\n",
    "print(\"Test set size:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_format(truelabels):\n",
    "    spacy_data = []\n",
    "\n",
    "    for index, row in tqdm(truelabels.iterrows(), total=len(truelabels), desc=\"Creating formatted data\"):\n",
    "        text = row['Cleaned Text']\n",
    "        org_name = row['True Organization']\n",
    "        if pd.isnull(org_name):\n",
    "            continue\n",
    "        \n",
    "        # escape special characters in the organization name\n",
    "        escaped_org_name = re.escape(org_name)\n",
    "        \n",
    "        # pattern to find the organization name followed by a comma or period, or at the end of text\n",
    "        pattern = rf\"\\b{escaped_org_name}\\b\"\n",
    "        \n",
    "        entities = []\n",
    "        \n",
    "        # find all matches \n",
    "        for match in re.finditer(pattern, text):\n",
    "            start_index = match.start()\n",
    "            end_index = match.end()\n",
    "            \n",
    "            # add the entity to the list\n",
    "            entities.append((start_index, end_index, 'ORG'))\n",
    "        \n",
    "        spacy_data.append([text, {'entities': entities}])\n",
    "    return spacy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first few entries of the training data\n",
    "train_data = get_spacy_format(train)\n",
    "test_data = get_spacy_format(test)\n",
    "print(test_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to see what words are marked as organizations\n",
    "for data in train_data:\n",
    "    text = data[0]\n",
    "    entities = data[1]['entities']\n",
    "    \n",
    "    print(\"Organization Name Indices:\")\n",
    "    for entity in entities:\n",
    "        start_index, end_index, entity_type = entity\n",
    "        org_name = text[start_index:end_index]\n",
    "        print(f\"Organization Name: {org_name}, Start Index: {start_index}, End Index: {end_index}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_organization_name(text):\n",
    "    # process text\n",
    "    doc = nlp(text)\n",
    "    # extract organization entities from the processed document\n",
    "    organizations = [ent.text for ent in doc.ents if ent.label_ == 'ORG']  # extract organization entities\n",
    "    if organizations:\n",
    "        # find most common organization name by counting found organizations\n",
    "        organization_counter = Counter(organizations)\n",
    "        most_common_organization = organization_counter.most_common(1)[0][0]\n",
    "        return most_common_organization\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notfinetuned = test\n",
    "\n",
    "df_notfinetuned['Predicted_Organization'] = df_notfinetuned['Cleaned Text'].apply(extract_organization_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pretrained_accuracy(df_notfinetuned):\n",
    "    predicted_orgs = list(df_notfinetuned['Predicted_Organization'])\n",
    "    true_orgs = list(df_notfinetuned['True Organization'])\n",
    "\n",
    "    correct_predictions = 0\n",
    "    for pred, truth in zip(predicted_orgs, true_orgs):\n",
    "        # normalize the data to lower case to ignore case sensitivity\n",
    "        pred = str(pred)\n",
    "        truth = str(truth)\n",
    "        pred = pred.lower().strip()\n",
    "        truth = truth.lower().strip()\n",
    "\n",
    "        # check for exact or partial match\n",
    "        if pred != 'None':\n",
    "            if pred == truth or pred in truth or truth in pred:\n",
    "                print(pred, truth)\n",
    "                correct_predictions += 1\n",
    "\n",
    "    # calculate accuracy\n",
    "    total_predictions = len(predicted_orgs)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return f\"Accuracy: {accuracy * 100:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pretrained_fuzzy_accuracy(df_notfinetuned):\n",
    "    predicted_orgs = list(df_notfinetuned['Predicted_Organization'])\n",
    "    true_orgs = list(df_notfinetuned['True Organization'])\n",
    "\n",
    "    correct_predictions = 0\n",
    "    threshold = 80 \n",
    "\n",
    "    # evaluate with fuzzy matching\n",
    "    for pred, truth in zip(predicted_orgs, true_orgs):\n",
    "        pred = str(pred).lower().strip()\n",
    "        truth = str(truth).lower().strip()\n",
    "\n",
    "        if pred != 'none':\n",
    "            match_score = fuzz.partial_ratio(pred, truth)\n",
    "            if match_score >= threshold:\n",
    "                correct_predictions += 1\n",
    "\n",
    "    # calculate accuracy\n",
    "    total_predictions = len(predicted_orgs)\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return f\"Accuracy: {accuracy * 100:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_pretrained_accuracy(df_notfinetuned)\n",
    "calculate_pretrained_fuzzy_accuracy(df_notfinetuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction presence for precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_presence(df_notfinetuned):\n",
    "    predicted_orgs = list(df_notfinetuned['Predicted_Organization'])\n",
    "    prediction_presence = []\n",
    "\n",
    "    for pred in predicted_orgs:\n",
    "        pred = str(pred).lower().strip()\n",
    "        \n",
    "        if pred and pred != 'none':  # ensure that 'none' predictions are treated as no prediction\n",
    "            prediction_presence.append(1)\n",
    "        else:\n",
    "            prediction_presence.append(0)\n",
    "\n",
    "    return prediction_presence\n",
    "\n",
    "spacy_prediction_presence = prediction_presence(df_notfinetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with 1 if organization is present in the text, 0 otherwise\n",
    "# see calculation of actuals in current_method notebook\n",
    "actuals = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "spacy_pretr_preds = spacy_prediction_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(predictions, actuals):\n",
    "    TP = sum(1 for actual, pred in zip(actuals, predictions) if actual == 1 and pred == 1)\n",
    "    FP = sum(1 for actual, pred in zip(actuals, predictions) if actual == 0 and pred == 1)\n",
    "    FN = sum(1 for actual, pred in zip(actuals, predictions) if actual == 1 and pred == 0)\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_s, recall_s = calculate_precision_recall(spacy_pretr_preds, actuals)\n",
    "\n",
    "print(f\"Precision SpaCy pretr: {precision_s:.2f}\")\n",
    "print(f\"Recall SpaCy pretr: {recall_s:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to see example of spacy labeling entities\n",
    "\n",
    "# doc = nlp(df_notfinetuned['Cleaned Text'][0])\n",
    "\n",
    "# spacy.displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best hyperparameters from hyperparameter tuning\n",
    "n_iter = 17\n",
    "batch_size = 16\n",
    "# learning_rate = 0.0001693938290758659\n",
    "nlp = spacy.load(\"nl_core_news_lg\")\n",
    "ner_categories = ['ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nlp.create_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/627 [00:00<?, ?it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"w samen voor boeiend onderwijstrinamiek is een lev...\" with entities \"[(344, 353, 'ORG'), (432, 441, 'ORG'), (448, 457, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "  6%|▌         | 37/627 [00:00<00:09, 62.12it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"accountantsverslag interactive pdf reportxx maart ...\" with entities \"[(1327, 1341, 'ORG'), (1729, 1743, 'ORG'), (1879, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 106/627 [00:01<00:05, 90.60it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1 voor jaarstukken 2020 versie ten behoeve van zie...\" with entities \"[(1654, 1658, 'ORG'), (2160, 2164, 'ORG'), (2345, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 21%|██        | 129/627 [00:01<00:05, 93.20it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1 jaarverslag en jaarrekening afeer 2020 afeer jaa...\" with entities \"[(30, 35, 'ORG'), (41, 46, 'ORG'), (134, 139, 'ORG...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 23%|██▎       | 143/627 [00:01<00:04, 104.20it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"gemeente ridderkerk accountantsverslag 2020 1 juli...\" with entities \"[(0, 19, 'ORG'), (117, 136, 'ORG'), (707, 726, 'OR...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 158/627 [00:01<00:04, 115.52it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"jaarverslag 2020 nlinbusiness1jaarverslag 2020 jaa...\" with entities \"[(118, 130, 'ORG'), (390, 402, 'ORG'), (459, 471, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 31%|███       | 195/627 [00:02<00:03, 117.32it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1verbruggen , silvana van : directiesecretariaat g...\" with entities \"[(49, 70, 'ORG'), (196, 217, 'ORG'), (585, 606, 'O...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 50%|█████     | 316/627 [00:03<00:02, 110.13it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"stichting de gruitpoort te doetinchem jaarrekening...\" with entities \"[(0, 23, 'ORG'), (144, 167, 'ORG'), (2272, 2295, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"financieel jaarverslag 2020 stichting koraal/two.o...\" with entities \"[(28, 44, 'ORG'), (81, 97, 'ORG'), (1889, 1905, 'O...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 55%|█████▌    | 345/627 [00:03<00:02, 117.12it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"jaar stukken 2020 u centraal pieterskerkhof 16 351...\" with entities \"[(92, 102, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"jaarstukken 2020 datum : 20-05-2021 * 21.201808 * ...\" with entities \"[(71, 89, 'ORG'), (1860, 1878, 'ORG'), (2511, 2529...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 57%|█████▋    | 358/627 [00:03<00:02, 118.67it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"jaardocument 2020 maastricht universitair medisch ...\" with entities \"[(117, 131, 'ORG'), (1532, 1546, 'ORG'), (1610, 16...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"jaarverslag 2020 enexis netbeheer b.v.pag_netbehee...\" with entities \"[(17, 38, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"horizon verbredenjaarverslag 2019horizon verbreden...\" with entities \"[(53, 58, 'ORG'), (144, 149, 'ORG'), (166, 171, 'O...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 66%|██████▌   | 411/627 [00:04<00:01, 122.50it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"jaarverslag 2019 2. jaarverslag 2019 | lantarenven...\" with entities \"[(39, 54, 'ORG'), (55, 70, 'ORG'), (354, 369, 'ORG...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 68%|██████▊   | 424/627 [00:04<00:01, 112.94it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"ww.aan-z.eui nfo @ aan-z.eum arkt 1 , 4571 bgaxel ...\" with entities \"[(3, 8, 'ORG'), (19, 24, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 72%|███████▏  | 450/627 [00:04<00:01, 114.26it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"stichting vrijwilligers en mantelzorg centrale alm...\" with entities \"[(0, 53, 'ORG'), (534, 587, 'ORG'), (3681, 3734, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 90%|████████▉ | 564/627 [00:05<00:00, 121.51it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"jaarverslag en jaarrekening 2020 werkvoorzieningss...\" with entities \"[(75, 82, 'ORG'), (102, 109, 'ORG'), (150, 157, 'O...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 601/627 [00:05<00:00, 146.20it/s]C:\\Users\\eSann\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"jaarstukken 2019 recreatieschap rottemeren ' a .-i...\" with entities \"[(17, 42, 'ORG'), (1815, 1840, 'ORG'), (1988, 2013...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "100%|██████████| 627/627 [00:05<00:00, 105.42it/s]\n",
      "100%|██████████| 17/17 [1:01:28<00:00, 216.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tok2vec': 0.0, 'morphologizer': 0.0, 'tagger': 0.0, 'parser': 0.0, 'lemmatizer': 0.0, 'ner': 30600.62902485548}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert training data into Example objects\n",
    "examples = []\n",
    "for text, annotations in tqdm(train_data):\n",
    "    examples.append(Example.from_dict(nlp.make_doc(text), annotations))\n",
    "\n",
    "# train the NER model\n",
    "losses = {}\n",
    "for itn in tqdm(range(n_iter)): \n",
    "    random.shuffle(examples)\n",
    "    for batch in minibatch(examples, size=batch_size):\n",
    "        nlp.update(batch, losses=losses)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.98%\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(test_data, nlp):\n",
    "    total_examples = len(test_data)\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for text, annotations in test_data:\n",
    "        # process the text with the NER model to extract entities\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # extract all predicted organizations from the document\n",
    "        predicted_orgs = [ent.text for ent in doc.ents if ent.label_ == 'ORG']\n",
    "        \n",
    "        if 'entities' in annotations and annotations['entities']:\n",
    "            start, end, label = annotations['entities'][0]\n",
    "            true_org = text[start:end]\n",
    "\n",
    "            # if there are predicted organizations, find the most common one\n",
    "            if predicted_orgs:\n",
    "                most_common_org = Counter(predicted_orgs).most_common(1)[0][0]\n",
    "            else:\n",
    "                most_common_org = None\n",
    "            \n",
    "            # compare the most common predicted organization with the true organization\n",
    "            if most_common_org: \n",
    "                if most_common_org.lower() == true_org.lower():\n",
    "                    correct_predictions += 1\n",
    "                elif most_common_org.lower() in true_org.lower():\n",
    "                    correct_predictions += 1\n",
    "                elif true_org.lower() in most_common_org.lower():\n",
    "                    correct_predictions += 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    accuracy = correct_predictions / total_examples\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy(test_data, nlp)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 46.10%\n"
     ]
    }
   ],
   "source": [
    "def calculate_fuzzy_accuracy(test_data, nlp, threshold=80):\n",
    "    total_examples = len(test_data)\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for text, annotations in test_data:\n",
    "        # process the text with the NER model to extract entities\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # extract all predicted organizations from the document\n",
    "        predicted_orgs = [ent.text for ent in doc.ents if ent.label_ == 'ORG']\n",
    "        \n",
    "        if 'entities' in annotations and annotations['entities']:\n",
    "            start, end, label = annotations['entities'][0]\n",
    "            true_org = text[start:end]\n",
    "\n",
    "            # if there are predicted organizations, find the most common one\n",
    "            if predicted_orgs:\n",
    "                most_common_org = Counter(predicted_orgs).most_common(1)[0][0]\n",
    "            else:\n",
    "                most_common_org = None\n",
    "            \n",
    "            # compare the most common predicted organization with the true organization\n",
    "            if most_common_org:\n",
    "                # normalize to lower case\n",
    "                most_common_org = most_common_org.lower().strip()\n",
    "                true_org = true_org.lower().strip()\n",
    "                \n",
    "                # fuzzy matching score\n",
    "                match_score = fuzz.partial_ratio(most_common_org, true_org)\n",
    "                \n",
    "                if match_score >= threshold:\n",
    "                    correct_predictions += 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    accuracy = correct_predictions / total_examples if total_examples > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_fuzzy_accuracy(test_data, nlp, threshold=80)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of document level accuracy\n",
    "For comparison between models with paired t-tests. See usage in current_method notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_examples = len(test_data)\n",
    "doc_acc = []\n",
    "\n",
    "print(total_examples)\n",
    "\n",
    "for text, annotations in test_data:\n",
    "    # Process the text with the NER model to extract entities\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract all predicted organizations from the document\n",
    "    predicted_orgs = [ent.text for ent in doc.ents if ent.label_ == 'ORG']\n",
    "    \n",
    "    if 'entities' in annotations and annotations['entities']:\n",
    "        # Find the true organization using the provided span (assumes there is only one true organization per text)\n",
    "        start, end, label = annotations['entities'][0]\n",
    "        true_org = text[start:end]\n",
    "\n",
    "        # If there are predicted organizations, find the most common one\n",
    "        if predicted_orgs:\n",
    "            most_common_org = Counter(predicted_orgs).most_common(1)[0][0]\n",
    "            if most_common_org.lower() == true_org.lower():\n",
    "                doc_acc.append(1)\n",
    "            elif most_common_org.lower() in true_org.lower():\n",
    "                doc_acc.append(1)\n",
    "            elif true_org.lower() in most_common_org.lower():\n",
    "                doc_acc.append(1)\n",
    "            else:\n",
    "                doc_acc.append(0)\n",
    "        else:\n",
    "            doc_acc.append(0)\n",
    "    else:\n",
    "        doc_acc.append(0)\n",
    "\n",
    "\n",
    "print(doc_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconddata = pd.read_csv('final_seconddata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get labeled format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating formatted data: 100%|██████████| 458/458 [00:00<00:00, 4087.22it/s]\n"
     ]
    }
   ],
   "source": [
    "second_labeled = get_spacy_format(seconddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    }
   ],
   "source": [
    "second_labeled = [entry for entry in second_labeled if len(entry[1]['entities']) > 0]\n",
    "\n",
    "print(len(second_labeled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_notfinetuned = seconddata\n",
    "\n",
    "df2_notfinetuned['Predicted_Organization'] = df2_notfinetuned['Cleaned Text'].apply(extract_organization_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_pretrained_accuracy(df_notfinetuned)\n",
    "calculate_pretrained_fuzzy_accuracy(df_notfinetuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_accuracy(second_labeled, nlp)\n",
    "calculate_fuzzy_accuracy(second_labeled, nlp, threshold=80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
